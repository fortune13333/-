# “链踪”项目 AI 功能深度解析

欢迎阅读“链踪”的AI功能指南。本项目深度集成了先进的人工智能技术，旨在将传统的网络配置管理从单纯的版本控制，提升到**智能化的分析、辅助与决策**层面。

本文档将为您详细阐明AI功能的工作原理、各项功能模块的用途，以及如何根据您的需求进行灵活配置。

---

## 1. 工作原理 (How It Works)

“链踪”的AI系统被设计为一个灵活的**“双模引擎”**，允许您在开箱即用的强大功能与完全自定义的解决方案之间自由选择。

### 1.1 双模引擎 (Dual-Mode Engine)

1.  **默认模式: Google Gemini**
    *   **核心**: 直接通过官方的 `@google/genai` SDK 调用 Google Gemini 模型。
    *   **优势**: 开箱即用，提供高质量的分析与生成能力。
    *   **要求**: 需要一个有效的 Google Gemini API 密钥。

2.  **自定义模式: 任意 API 端点**
    *   **核心**: 允许您将AI请求指向**任何一个自定义的HTTP API端点**。
    *   **优势**: 极高的灵活性。您可以接入公司内部自研的AI模型、部署第三方开源模型（如 Llama、DeepSeek），或者创建一个“适配器”来调用其他商业AI服务（如 OpenAI的ChatGPT、月之暗面的Kimi等）。
    *   **要求**: 您的自定义API端点必须遵循“链踪”定义的 **API合约**。

### 1.2 API 合约 (The API Contract)

为了让“自定义模式”能够正常工作，您的API服务必须像一个遵守约定的“加工厂”。前端应用会发送一个标准格式的“订单”（HTTP请求），而您的服务必须返回一个标准格式的“成品”（HTTP响应）。

**以“AI 智能分析”功能为例：**

*   **前端会发送 (Request):**
    一个 `POST` 请求，请求体 (body) 为以下JSON格式：
    ```json
    {
      "previousConfig": "旧的设备配置文本...",
      "newConfig": "新的设备配置文本...",
      "changeDescription": "可选的变更描述，比如'回滚到版本X'"
    }
    ```

*   **您的API服务必须返回 (Response):**
    一个状态码为 `200 OK` 的响应，响应体 (body) 为以下JSON格式：
    ```json

    {
      "diff": "AI生成的差异对比文本...",
      "summary": "AI生成的一句话中文总结...",
      "analysis": "AI生成的详细中文分析...",
      "security_risks": "AI生成的安全风险评估..."
    }
    ```

只要您的服务能遵守这个“输入-输出”的约定，无论背后是哪个AI模型在工作，“链踪”前端都能完美地解析和显示结果。其他AI功能（如命令生成、配置体检）也有其各自类似的简单合约。

### 1.3 如何接入 ChatGPT 或 DeepSeek？

直接将第三方API的URL（如 `https://api.openai.com/v1/chat/completions`）填入配置是**行不通的**，因为它们的API格式与“链踪”的合约不同。

**正确的解决方案是：创建一个“适配器”或“中间件”服务。**

这个适配器服务（可以用几行Node.js或Python代码轻松实现）的工作流程是：
1.  **接收** “链踪”前端发来的标准请求。
2.  **转换** 请求内容，编写合适的Prompt，并构造成目标API（如ChatGPT）所需的格式。
3.  **调用** 目标API。
4.  **接收** 目标API的响应。
5.  **解析** 响应内容，并将其**重组**成“链踪”前端期望的标准JSON格式。
6.  **返回** 给“链踪”前端。

---

## 2. AI 功能模块详解

“链踪”将AI能力拆分为了三个独立的、可按需启用的功能模块。

### 2.1 AI 智能分析 (AI Smart Analysis)

*   **触发时机**: 当您在设备详情页点击“提交”按钮，准备记录一个新的配置版本时触发。
*   **功能**: 仿佛一位资深的网络专家在您身边进行Code Review。它会深入分析**新旧配置之间的差异**，并自动生成一份全面的分析报告。
*   **核心产出**:
    *   **`diff`**: 一份清晰的、逐行的配置差异对比。
    *   **`summary`**: 一句高度概括的中文变更摘要，让您一目了然此次变更的核心目的。
    *   **`analysis`**: 一段详细的技术分析，用通俗的语言解释了变更的具体内容和可能带来的影响。
    *   **`security_risks`**: 一份专业的安全评估，指出变更中可能存在的安全隐患或最佳实践违规。

### 2.2 AI 命令生成 (AI Command Generation)

*   **触发时机**: 由用户在设备详情页的“AI 助手”输入框中主动发起。
*   **功能**: 您的私人网络命令专家。它能将您的**自然语言指令**（例如：“为VLAN 10添加端口G0/1”）实时翻译成目标设备（如Cisco IOS, Huawei VRP）能够识别和执行的**精确配置命令**。
*   **上下文感知**: AI在生成命令时，会参考当前设备的类型和已有的配置，以确保生成的命令更准确、更贴合实际场景。

### 2.3 AI 配置体检 (AI Configuration Check)

*   **触发时机**: 由用户在设备详情页点击“AI 配置体检”按钮主动发起。
*   **功能**: 一位7x24小时待命的**网络安全审计师**。它会对您当前正在编辑的**完整配置**进行一次全面的健康和安全扫描。
*   **核心产出**:
    *   一份详细的“体检报告”，指出配置中可能存在的**安全漏洞**（如弱密码、不安全的协议）、**最佳实践违规**（如缺少日志记录）、以及**逻辑错误或不一致**之处，并提供可行的优化建议。

---

## 3. 配置方法

所有AI相关的配置都在项目根目录下的 `.env` 文件中完成。

### 3.1 基础配置：使用 Google Gemini (默认)

这是最简单、最直接的使用方式。

1.  在项目根目录下，找到 `env.txt` 文件，并将其重命名为 `.env`。
2.  打开 `.env` 文件，将您的 Google Gemini API 密钥粘贴进去：
    ```env
    API_KEY="AIzaSy...your...key...here"
    ```
3.  **重启开发服务器** (如果在运行 `npm run dev`，请按 `Ctrl+C` 停止后重新运行)。

完成！现在所有AI模块都将默认使用 Google Gemini。

### 3.2 高级配置：使用自定义服务接口

如果您有自己的AI服务，或者已经为第三方AI服务创建了“适配器”，可以使用此方法。

1.  打开 `.env` 文件。
2.  根据您需要覆盖的AI模块，填入对应的URL。共有三个环境变量可供配置：
    ```env
    # 用于“AI 智能分析”
    VITE_ANALYSIS_API_URL=http://your-server.com/api/analyze

    # 用于“AI 命令生成”
    VITE_COMMAND_GENERATION_API_URL=http://your-server.com/api/generate

    # 用于“AI 配置体检”
    VITE_CONFIG_CHECK_API_URL=http://your-server.com/api/check
    ```

**⭐ 重要原则：`.env` 文件中的URL拥有最高优先级。**

一旦您在 `.env` 文件中设置了上述任何一个URL，它将**强制覆盖**所有其他设置（包括UI中的手动输入）。在设置界面，对应的输入框将变为**只读**状态，明确告知该配置由环境文件管理。

这确保了在团队或生产环境中，配置的统一性和安全性。